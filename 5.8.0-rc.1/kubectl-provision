#!/usr/bin/env bash

: '
Access to this file is granted under the SCONE COMMERCIAL LICENSE V1.0

Any use of this product using this file requires a commercial license from scontain UG, www.scontain.com.

Permission is also granted  to use the Program for a reasonably limited period of time  (but no longer than 1 month)
for the purpose of evaluating its usefulness for a particular purpose.

THERE IS NO WARRANTY FOR THIS PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING
THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED,
INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.

THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE,
YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED ON IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY
MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL,
INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM INCLUDING BUT NOT LIMITED TO LOSS
OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE
WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.

Copyright (C) 2022 scontain.com
'

set -e

export K_PROVISION_VERSION="5.8.0-rc.1"
export RED='\e[31m'
export BLUE='\e[34m'
export ORANGE='\e[33m'
export NC='\e[0m' # No Color

function verbose () {
    if [[ $V -eq 1 ]]; then
        echo -e "${BLUE}- $@${NC}"
    fi
}

function warning () {
    echo -e "${ORANGE}WARNING: $@${NC}"
}

function error_exit() {
  trap '' EXIT
  echo -e "${RED}$1${NC}" 
  exit 1
}

function set_platform_ids {
  export PLATFORM_IDS=$(kubectl get LAS -A -o json | jq '.items[].status.nodes[].publicKey' | tr -d '"' | sort | uniq | awk '{ print "platforms: [" $1 "]" }')
}

# print an error message on an error exit
trap 'last_command=$current_command; current_command=$BASH_COMMAND' DEBUG
trap 'if [ $? -ne 0 ]; then echo -e "${RED}\"${last_command}\" command failed - exiting.${NC}"; if [ $SERVICE_PID != 0 ] ; then kill $SERVICE_PID ; fi ; fi' EXIT


# a precheck to ensure that all directories exist (since we might need sudo to create)

function check_prerequisites() {
    exit_msg=""
    verbose "Checking that we have access to kubectl"
    if ! command -v kubectl &> /dev/null
    then
        exit_msg="Command 'kubectl' not found!"
        echo -e "${RED}${exit_msg}${NC}"
        echo -e "- ${ORANGE}Please install 'kubectl'- see https://kubernetes.io/docs/tasks/tools/${NC}"
    fi

    verbose "Checking that we have access to helm"
    if ! command -v helm &> /dev/null
    then
        exit_msg="Command 'helm' not found!"
        echo -e "${RED}${exit_msg}${NC}"
        echo -e "- ${ORANGE}Please install  'helm' - see https://helm.sh/docs/intro/install/${NC}"
    fi

    exit_msg=""
    verbose "Checking that we have access to jq"
    if ! command -v jq &> /dev/null
    then
        exit_msg="Command 'jq' not found!"
        echo -e "${RED}${exit_msg}${NC}"
        echo -e "- ${ORANGE}Please install 'jq'- see https://stedolan.github.io/jq/download/${NC}"
    fi

    verbose "Checking that you have access to a Kubernetes cluster."
    if ! kubectl get pods &> /dev/null
    then
        echo -e "${RED}It seems that you do not have access to a Kubernetes cluster!${NC}"
        echo -e "- ${ORANGE}Please ensure that you have access to a Kubernetes cluster${NC}"
        exit_msg="No access to Kubernetes cluster!"
    fi


    if [[ "$exit_msg" != "" ]] ; then
        error_exit "$exit_msg"
    fi

    verbose "Checking that required directories exist."
    mkdir -p "$TARGET_DIR/owner-config" || error_exit "Failed to create directory '$TARGET_DIR/owner-config' - please create manually - this might require sudo"
    mkdir -p "$TARGET_DIR/identity" || error_exit "Failed to create directory '$TARGET_DIR/identity' - please create manually - this might require sudo"


}

function check_if_provisioned {

  CAS_CLIENT_PORT=8081
  verbose "CAS SVC name = $NAME)"

  if ! kubectl get cas "$NAME" -n "$NAMESPACE" 2> /dev/null >/dev/null
  then
    verbose "No CAS $CAS is running in namespace $NAMESPACE"
    trap '' EXIT
    exit 1
  fi
 
  kubectl port-forward service/$NAME $CAS_CLIENT_PORT:$CAS_CLIENT_PORT --namespace "$NAMESPACE" --address=0.0.0.0 > /dev/null &
  SERVICE_PID=$!
  sleep 5
  kill -0 $SERVICE_PID &>/dev/null || error_exit "It looks like that either port $CAS_CLIENT_PORT is not available on your local machine or the service $SVCNAME is not running. Bailing!"


  RESULT=$(docker run -it --rm \
      --network=host \
      --add-host=host.docker.internal:host-gateway \
      -v "$TARGET_DIR"/identity:/identity \
      -v "$TARGET_DIR"/owner-config:/owner-config \
      -e SCONE_CLI_CONFIG="/identity/config.json" \
      -e SCONE_CAS_ADDR="host.docker.internal" \
      -e SCONE_CLI_MRENCLAVE="$SCONE_CLI_MRENCLAVE" \
      -e POLICY_NAME="$POLICY_NAME" \
      -e SCONE_LOG="ERROR" \
      $IMAGE_REPO/cas \
      bash -c 'scone cas attest -G host.docker.internal >/dev/null 2>/dev/null; scone cas set-default host.docker.internal ;  scone session read provisioned 2> /dev/null ; if [ $? != 0 ] ; then  echo "CAS is NOT provisioned" ; else  echo "CAS is provisioned" ; fi ')

  verbose "$RESULT"
  kill $SERVICE_PID

  if [[ "$RESULT" == "CAS is NOT provisioned" ]] ; then
    echo "$RESULT" "CAS is provisioned"
    trap '' EXIT
    exit 1
  fi
}

function print_cas_keys {

  CAS_CLIENT_PORT=8081
  verbose "CAS SVC name = $NAME"

  if ! kubectl get cas "$NAME" -n "$NAMESPACE" 2> /dev/null >/dev/null
  then
    warning "No CAS $CAS is running in namespace $NAMESPACE"
    trap '' EXIT
    exit 1
  fi
 
  kubectl port-forward service/$NAME $CAS_CLIENT_PORT:$CAS_CLIENT_PORT --namespace "$NAMESPACE" --address=0.0.0.0 > /dev/null &
  SERVICE_PID=$!
  sleep 5
  kill -0 $SERVICE_PID &>/dev/null || error_exit "It looks like that either port $CAS_CLIENT_PORT is not available on your local machine or the service $SVCNAME is not running. Bailing!"


  docker run -it --rm \
      --network=host \
      --add-host=host.docker.internal:host-gateway \
      -v "$TARGET_DIR"/identity:/identity \
      -v "$TARGET_DIR"/owner-config:/owner-config \
      -e SCONE_CLI_CONFIG="/identity/config.json" \
      -e SCONE_CAS_ADDR="host.docker.internal" \
      -e SCONE_CLI_MRENCLAVE="$SCONE_CLI_MRENCLAVE" \
      -e POLICY_NAME="$POLICY_NAME" \
      -e SCONE_LOG="ERROR" \
      $IMAGE_REPO/cas \
    sh -c "set -e ; scone cas attest -G host.docker.internal > /dev/null 2> /dev/null; scone cas set-default host.docker.internal ; echo -en 'export CAS_KEY=\"' ; scone cas show-identification -c  | tr -d '\n'  ; echo -en '\"\nexport CAS_SOFTWARE_KEY=\"' ; scone cas show-identification -s | tr -d '\n' ; echo -en '\"\nexport CAS_SESSION_ENCRYPTION_KEY=\"'; scone cas show-identification --session-encryption-key  | tr -d '\n' ; echo -en '\"\n' "

  echo "export CAS_URL=\"$NAME.$NAMESPACE\""

  kill $SERVICE_PID
  trap '' EXIT
  exit 0

}

if [[ "$DEFAULT_NAMESPACE" == "" ]] ; then
  export DEFAULT_NAMESPACE="default" # Default Kubernetes namespace to use
else
  warning "Using external DEFAULT_NAMESPACE=$DEFAULT_NAMESPACE"
fi
NAMESPACE="$DEFAULT_NAMESPACE"

if [[ "$DEFAULT_DCAP_KEY" == "" ]] ; then
  export export DEFAULT_DCAP_KEY="aecd5ebb682346028d60c36131eb2d92"  # Default DCAP API Key to used
else
  warning "Using external DEFAULT_DCAP_KEY=$DEFAULT_DCAP_KEY"
fi

if [[ "$IMAGE_REPO" == "" ]] ; then
  IMAGE_REPO="registry.scontain.com/scone.cloud"
else
  warning "Using external IMAGE_REPO=$IMAGE_REPO"
fi

if [[ "$DEFAULT_MANIFEST" != "" ]] ; then
    warning "Using external DEFAULT_MANIFEST=$DEFAULT_MANIFEST"
fi

if [[ "$VERSION" == "" ]] ; then
  VERSION="latest"
else
  warning "Using external VERSION=$VERSION"
fi


if [[ "$TARGET_DIR" == "" ]] ; then
  TARGET_DIR="$HOME/.cas" # Default target directory
else
  warning "Using external TARGET_DIR=$TARGET_DIR"
fi

# OWNER_FILE=""  # No default owner config file

SERVICE_PID=0
help_flag="--help"
ns_flag="--namespace"
ns_short_flag="-n"
dcap_flag="--dcap-api"
dcap_short_flag="-d"
verbose_short_flag="-v"
verbose_flag="--verbose"
owner_flag="--owner-config"
owner_short_flag="-o"
debug_flag="--debug"
debug_short_flag="-d"
debug=""
target_flag="--target"
file_short_flag="-f"
file_flag="--filename"
version_flag="--set-version"
no_backup_flag="--no-backup"
webhook_flag="--webhook"
print_version_flag="--version"
is_provisioned_flag="--is-provisioned"
print_caskeys_flag="--print_caskeys"

DCAP_KEY="$DEFAULT_DCAP_KEY"  # Default DCAP API Key to used
SVC=""
# NAME is the name of the cas
NAME=""
VAULT_NAME=""
NO_BACKUP=0
WEBHOOK=""
is_provisioned=0
print_caskeys=0

usage ()
{
  echo ""
  echo "Usage:"
  echo "  kubectl provision SVC [NAME] [$ns_flag <kubernetes-namespace>] [$dcap_flag <API Key>] [$owner_flag <owner config>] [$verbose_flag] [$help_flag]"
  echo ""
  echo "Arguments:"
  echo "  Service to provision: SVC = cas | vault"
  echo "    - cas:   provision CAS instance using the SCONE operator"
  echo "    - vault: provision a confidential Vault instance using the SCONE operator. If no cas named cas-NAME exists, it is"
  echo "             also created and provisioned, together with the vault. If such a cas already exists, it is not provisioned."
  echo ""
  echo "  Name of the service: NAME"
  echo "    - If no name is specified, we set NAME=SVC"
  echo ""
  echo "Options:"
  echo "    $ns_short_flag | $ns_flag"
  echo "                  The Kubernetes namespace in which the service should be deployed on the cluster."
  echo "                  Default value: \"$DEFAULT_NAMESPACE\""
  echo "    $dcap_flag | $dcap_short_flag"
  echo "                  DCAP API Key - recommended when provisioning CAS. We use a default otherwise. Ignored for all other services."
  echo "                  Default value is a shared API key that might stop working at any point in time: DCAP KEY=\"$DCAP_KEY\""
  echo "    $owner_flag | $owner_short_flag"
  echo "                  Provide a specific owner config when provisioning the CAS instance."
  echo "                  By default, we provision for a NodePort. We currently do not support"
  echo "                  providing an owner config for LoadBalancer services."
  echo "    $target_flag"
  echo "                  Specify target directory for generated manifests and owner IDs. Default path=\"$TARGET_DIR\"."
  echo "    $no_backup_flag"
  echo "                  Create and provision a cas with the backup-controller disabled."
  echo "    $verbose_short_flag | $verbose_flag"
  echo "                  Enable verbose output"
  echo "    $debug_flag | debug_short_flag"
  echo "                  Create debug image instead of a production image"
  echo "    $webhook_flag <URL>"
  echo "                  Forward entries of the CAS audit log to the given URL"
  echo "    $file_flag | file_short_flag"
  echo "                  file or url	that contains the manifest to apply (default is \$\"DEFAULT_MANIFEST\")"
  echo "    $is_provisioned_flag"
  echo "                  Checks if CAS is already provisioned and exists: Exits with an error in case it was not yet provisioned."
  echo "    $print_caskeys_flag"
  echo "                  Prints the CAS Key, the CAS Software Key and the CAS encryption key."
  echo "    $version_flag VERSION"
  echo "                  Set the version of CAS"
  echo "    $help_flag"
  echo "                  Output this usage information and exit."
  echo "    $print_version_flag"
  echo "                  Print version ($K_PROVISION_VERSION) and exit."
  echo ""
  echo "Default Configuration: "
  echo "  - VERSION=\"$VERSION\""
  echo "  - DEFAULT_MANIFEST=\"$DEFAULT_MANIFEST\""
  echo "  - DEFAULT_NAMESPACE=\"$DEFAULT_NAMESPACE\""
  echo "  - DEFAULT_DCAP_KEY=\"$DEFAULT_DCAP_KEY\""
  echo "  - TARGET_DIR=\"$TARGET_DIR\""
}


##### Parsing arguments

while [[ "$#" -gt 0 ]]; do
  case $1 in
    ${ns_flag} | ${ns_short_flag})
      NAMESPACE="$2"
      if [ ! -n "${NAMESPACE}" ]; then
        usage
        error_exit "Error: The namespace '$NAMESPACE' is invalid."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${webhook_flag})
      WEBHOOK="$2"
      if [ ! -n "${WEBHOOK}" ]; then
        usage
        error_exit "Error: Please specify a valid WEBHOOK ('$WEBHOOK' is invalid)."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${dcap_flag} | ${dcap_short_flag})
      DCAP_KEY="$2"
      if [ ! -n "${DCAP_KEY}" ]; then
        usage
        error_exit "Error: Please specify a valid DCAP_KEY ('$DCAP_KEY' is invalid)."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${owner_flag} | ${owner_short_flag})
      OWNER_FILE="$2"
      if [ ! -n "${OWNER_FILE}" ]; then
        usage
        error_exit "Error: Please specify a valid owner file ('$OWNER_FILE' is invalid)."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${target_flag})
      TARGET_DIR="$2"
      if [ ! -w "${TARGET_DIR}" ]; then
        usage
        error_exit "Error: Please specify a valid owner file ('$TARGET_DIR' is not writeable)."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${verbose_flag}|${verbose_short_flag})
      V=1
      shift # past argument
      ;;
    ${no_backup_flag})
      NO_BACKUP=1
      shift # past argument
      ;;
    ${debug_flag} | ${debug_short_flag})
      set -x
      shift # past argument
      ;;
    ${version_flag})
      VERSION="$2"
      if [ ! -n "${VERSION}" ]; then
        usage
        error_exit "Error: Please specify a valid VERSION ('$VERSION' is invalid)."
      fi
      shift # past argument
      shift || true # past value
      ;;
    ${print_version_flag})
      echo $K_PROVISION_VERSION
      exit 0
      ;;
    ${is_provisioned_flag})
      is_provisioned=1
      shift # past argument
      ;;
    ${print_caskeys_flag})
      print_caskeys=1
      shift # past argument
      ;;
    $help_flag)
      usage
      exit 0
      ;;
    *)
      if [[ "${SVC}" == "" ]]; then
        SVC="$1"
      elif [[ "${NAME}" == "" ]]; then
        NAME="$1"
      else
        usage
        error_exit "Error: Unknown parameter passed: $1";
      fi
      shift # past argument
      ;;
  esac
done

if [[ "${SVC}" != "cas" && "${SVC}" != "vault"  ]]; then
    usage
    error_exit "Error: Please specify a valid SVC ('$SVC' is invalid)."
fi

if [[ "$NAME" == "" ]] ; then
  verbose "No service NAME specified - using '$SVC' as NAME"
  NAME="$SVC"
fi

if [[ "${SVC}" == "vault" ]]; then
  VAULT_NAME="$NAME"
  NAME="cas-${VAULT_NAME}"
fi

if ! kubectl get namespace "$NAMESPACE" > /dev/null 2>/dev/null
then
  error_exit "Namespace '$NAMESPACE' does not exist."
fi

check_prerequisites

if [[ "${SVC}" == "vault" ]]; then
  verbose "checking whether Vault $VAULT_NAME already exists"
  EXISTS=1 kubectl get vault "$VAULT_NAME" --namespace "$NAMESPACE" &>/dev/null || EXISTS=0
  if [[ $EXISTS != 0 ]] ; then
    error_exit "The vault CR '$VAULT_NAME' already exists in namespace '$NAMESPACE'. We currently do not support provisioning an existing vault."
  fi
fi

if [ $is_provisioned == 1 ]
then
  check_if_provisioned
  exit 0
fi

if [ $print_caskeys == 1 ]
then
  print_cas_keys
  exit 0
fi



verbose "Checking if CAS '$NAME' already exists"

IMAGE=""
EXISTS=1  JSON=$(kubectl get cas "$NAME" --namespace "$NAMESPACE" -o json 2>/dev/null) || EXISTS=0

if [[ $EXISTS == 1 ]] ; then
  IMAGE=$(echo $JSON | jq '(.spec.image)' | tr -d '"' | jq -R '. | sub( "(?<image>[^':']*):(?<tag>.*)" ; "\(.image)")' | tr -d '"' )
  TAG=$(echo $JSON | jq '(.spec.image)' | tr -d '"' | jq -R '. |   sub( "(?<image>[^':']*):(?<tag>.*)" ; "\(.tag)")' | tr -d '"' )
  if [[ "$IMAGE" == "null" || "$IMAGE" == "" ]] ; then
    error_exit "Cannot determine image name of CAS '$NAME' in namespace '$NAMESPACE'" 
  fi

  if [[ "$IMAGE" == "$TAG" ]] ; then
    warning "CAS Image '$IMAGE' of CAS  $NAME in namespace $NAMESPACE has no tag specified!"
    IMAGE="$IMAGE:latest"
  else
    verbose "CAS Image '$IMAGE' has tag '$TAG'"
    IMAGE="$IMAGE:$TAG"
  fi
  
  EXPECTED_IMAGE="$IMAGE_REPO/cas:$VERSION"
  if [[ "$IMAGE" != "$EXPECTED_IMAGE"  ]] ; then
    error_exit "Expected CAS Image '$EXPECTED_IMAGE' but retrieved  '$IMAGE' - exiting!"
  else
    IMAGE_BACKUP_CONTROLLER="$IMAGE_REPO/backup-controller:$VERSION"
  fi
else
  IMAGE="$IMAGE_REPO/cas:$VERSION"
  IMAGE_BACKUP_CONTROLLER="$IMAGE_REPO/backup-controller:$VERSION"
fi

verbose "CAS Backup Image is '$IMAGE_BACKUP_CONTROLLER'"

if [[ $EXISTS == 0 ]] ; then
  verbose "CAS $NAME does not exists - creating it"

  export SVC_DNS_NAME="$NAME.$NAMESPACE.svc.cluster.local"
  if kubectl get pvc "database-$NAME-0"  --namespace "$NAMESPACE" 2> /dev/null 1> /dev/null ; then
    warning "Volume database-$NAME-0 already exists - provision of CAS for existing volume not supported: We do not want to overwrite existing database"
    exit 1
  fi


  if [[ -d $NAME ]] ; then
      warning "Directory $NAME already exists - we cannot provision for same NAME again. Delete $NAME or use a different name."
      exit 1
  fi

  export manifest_provsioning="$TARGET_DIR/owner-config/cas-$NAMESPACE-$NAME-$VERSION-provisioning-step.yaml"

  verbose "Creating manifest '$manifest_provsioning' for CAS provsioning"

# next version: USE default external  manifest -> which can use $NAME and $NAMESPACE or fixed names

  cat > "$manifest_provsioning" <<EOF
apiVersion: services.scone.cloud/v1beta1
kind: CAS
metadata:
  name: $NAME
  namespace: $NAMESPACE
spec:
  image: $IMAGE
  imagePullSecrets:
    - name: sconeapps
  service:
    type: NodePort
  imagePullPolicy: Always
  persistence:
    enabled: true
  databaseSnapshots:
    enabled: true
    persistence:
      enabled: true
  podAnnotations:
    scone-operator/inject-pull-secret:  "true"
  backup-controller:
    enabled: false
EOF

  verbose "Creating/Applying CAS CR for Provisioning"
  kubectl apply -f "$manifest_provsioning" || error_exit "Creation of CAS Manifest '$manifest_provsioning' failed."
else
  verbose "CAS $NAME already exists - trying to provision it"
fi

POD=""
until [[ $POD != "" ]]
do
     verbose "Waiting for CAS $NAME in Namespace $NAMESPACE to start"
     sleep 5
     POD=`kubectl get pod --selector "app.kubernetes.io/instance=$NAME,app.kubernetes.io/name=cas" -n "$NAMESPACE" | tail -1 | awk '{ print $1 }'` || echo "..."
done

verbose "Found POD '$POD'"

verbose "determining the CAS address"

SVCNAME=`kubectl get svc --namespace "$NAMESPACE" --selector "app.kubernetes.io/instance=$NAME,app.kubernetes.io/name=cas" | tail -1 | awk '{ print $1 }'`
export SCONE_CAS_ADDR=$(kubectl get svc --namespace "$NAMESPACE" "$SVCNAME" --template "{{ .spec.clusterIP }}")
export CAS_CLIENT_PORT=8081

verbose " CAS address = $SCONE_CAS_ADDR (SVC name = $SVCNAME)"

if [[ "$SCONE_CAS_ADDR" == "" ]] ; then
   error_exit "Failed to determine IP address of service $SVCNAME in namespace $NAMESPACE"
fi

# If cas already existed and we are provisioning vault we assume the cas was already provisioned
if [[ $EXISTS == 0 || "${SVC}" == "cas" ]] ; then

verbose "Retrieving CAS_KEY_HASH AND CAS_PROVISIONING_TOKEN from log of pod '$POD' in namespace '$NAMESPACE'"

RETRY=20
until kubectl logs $POD --namespace "$NAMESPACE" | grep "CAS key hash"
do
    sleep 2
    verbose "Waiting for CAS key"
    RETRY=$((RETRY - 1))
    if [[ $RETRY == 0 ]] ; then
      error_exit "Cannot retrieve CAS_KEY_HASH from log of CAS $NAME. Bailing."
    fi
done

export CAS_KEY_HASH=$(kubectl logs "$POD"  --namespace "$NAMESPACE" | grep "CAS key hash" | awk '{ print $7 } ')
export CAS_PROVISIONING_TOKEN=$(kubectl logs "$POD"  --namespace "$NAMESPACE" | grep "CAS provisioning token" | awk ' { print $7 } ')

echo CAS_PROVISIONING_TOKEN=$CAS_PROVISIONING_TOKEN
echo CAS_KEY_HASH=$CAS_KEY_HASH

if [[ "$CAS_PROVISIONING_TOKEN" == "" ]] ; then
  if [[ $EXISTS == 0 || "${SVC}" == "cas" ]] ; then
    error_exit "Cannot determine the provisioning token of CAS $NAME. Bailing."
  fi
fi
if [[ "$CAS_KEY_HASH" == "" ]] ; then
  if [[ $EXISTS == 0 || "${SVC}" == "cas" ]] ; then
    error_exit "Cannot determine the CAS_KEY of CAS $NAME. Bailing."
  fi
fi

verbose "Provisioning service 'cas': NAME = '$NAME' in namespace '$NAMESPACE' using DCAP-API Key '$DCAP_KEY'"

if [[ "$DCAP_KEY" == "$DEFAULT_DCAP_KEY" ]] ; then
  warning  "No DCAP API Key specified! Using default - this is not recommended for production!"
fi

if [[ "$WEBHOOK" != "" ]] ; then
  SINK="network"
  WEBURL="url = \"$WEBHOOK\""
else
  SINK="file"
  WEBURL=""
fi

CONFIG_FILE="$TARGET_DIR/owner-config/config.toml"
cat > "$CONFIG_FILE" <<EOF
[api_identity]
common_name = "$SVCNAME"
alt_names = ["$POD",  "$POD.$NAMESPACE.svc.cluster.local", "$POD.default",  "$SVCNAME.$NAMESPACE.svc.cluster.local", "$SVCNAME.default", "localhost", "$SCONE_CAS_ADDR"]

[dcap]
subscription_key = "$DCAP_KEY"

[audit_log]
mode = "signed"
sink = "$SINK"
$WEBURL
EOF

sleep 5
kubectl port-forward service/$SVCNAME $CAS_CLIENT_PORT:$CAS_CLIENT_PORT --namespace "$NAMESPACE" --address=0.0.0.0 &
SERVICE_PID=$!
sleep 5
kill -0 $SERVICE_PID &>/dev/null || error_exit "It looks like that either port $CAS_CLIENT_PORT is not available on your local machine or the service $SVCNAME is not running. Bailing!"

export SCONE_CLI_MRENCLAVE="$(docker run -t --rm --entrypoint scone -e SCONE_HASH=1 registry.scontain.com/scone.cloud/backup-controller cas | tr -d '\r')"
export POLICY_NAME="$NAME-backup-controller-$RANDOM$RANDOM"

docker run -it --rm \
    --network=host \
    --add-host=host.docker.internal:host-gateway \
    -v "$TARGET_DIR/"/identity:/identity \
    -v "$TARGET_DIR"/owner-config:/owner-config \
    -e SCONE_CLI_CONFIG="/identity/config.json" \
    -e CAS_KEY_HASH="$CAS_KEY_HASH" \
    -e CAS_PROVISIONING_TOKEN="$CAS_PROVISIONING_TOKEN" \
    -e SCONE_CAS_ADDR="host.docker.internal" \
    -e SCONE_CLI_MRENCLAVE="$SCONE_CLI_MRENCLAVE" \
    -e POLICY_NAME="$POLICY_NAME" \
    $IMAGE_REPO/sconecli scone cas provision host.docker.internal \
    -c $CAS_KEY_HASH \
    --token $CAS_PROVISIONING_TOKEN \
    --config-file /owner-config/config.toml \
    with-attestation \
    --accept-group-out-of-date \

sed 's/^/          /' "$TARGET_DIR/identity/config.json" >  "$TARGET_DIR/identity/owner_id_${SVCNAME}_$NAMESPACE.json"
export OWNER_IDENTITY=$(sed "s/host.docker.internal/$SVCNAME.$NAMESPACE/" "$TARGET_DIR/identity/owner_id_${SVCNAME}_$NAMESPACE.json")
echo "$OWNER_IDENTITY" > "$TARGET_DIR/identity/owner_id_${SVCNAME}_$NAMESPACE.json"

BACKUP_POLICY="$TARGET_DIR/identity/backup-controller-session-$POLICY_NAME.yaml"
set_platform_ids
cat > "$BACKUP_POLICY" <<EOF
name: $POLICY_NAME
version: "0.3.10"

security:
  attestation:
    tolerate: [debug-mode, outdated-tcb]

services:
  - name: register
    image_name: cli
    # optional: 
    #$PLATFORM_IDS
    attestation:
      mrenclave:
        - $SCONE_CLI_MRENCLAVE
    command: "scone cas register-backup @@3"
    environment:
      SCONE_MODE: hw
      SCONE_LOG: error
      SCONE_CLI_CONFIG: /etc/owner-identity.json
      \@\@SCONE_LAS_ADDR: ""
    pwd: /

images:
  - name: cli
    injection_files:
      - path: /etc/owner-identity.json
        content: |
$OWNER_IDENTITY
EOF

PROVISIONED_POLICY="$TARGET_DIR/identity/provisioned.yaml"
cat > "$PROVISIONED_POLICY" <<EOF
name: provisioned
version: "0.3.10"
predecessor:

access_policy:
  read:
    - ANY
  update:
    - CREATOR
  create_sessions:
    - CREATOR
EOF


docker run -it --rm \
    --network=host \
    --add-host=host.docker.internal:host-gateway \
    -v "$TARGET_DIR"/identity:/identity \
    -v "$TARGET_DIR"/owner-config:/owner-config \
    -e SCONE_CLI_CONFIG="/identity/config.json" \
    -e SCONE_CAS_ADDR="host.docker.internal" \
    -e SCONE_CLI_MRENCLAVE="$SCONE_CLI_MRENCLAVE" \
    -e POLICY_NAME="$POLICY_NAME" \
    $IMAGE_REPO/cas \
    sh -c "set -e ; scone cas attest -G host.docker.internal; scone cas set-default host.docker.internal ; scone session create /identity/backup-controller-session-$POLICY_NAME.yaml ; echo Exit: '$?' ; scone session create /identity/provisioned.yaml ; echo Exit: '$?' ; echo -en '\n${ORANGE}PUBLIC CAS_KEY=${NC}' ; scone cas show-identification -c ; echo -en '${ORANGE}PUBLIC CAS_SOFTWARE_KEY=${NC}' ; scone cas show-identification -s ; echo -en '${ORANGE}PUBLIC CAS_SESSION_ENCRYPTION_KEY=${NC}'; scone cas show-identification --session-encryption-key"

# next version: use encrypted policy and upload encrypted policy

kubectl get cas $NAME  --namespace "$NAMESPACE"

export cas_manifest="$TARGET_DIR/owner-config/cas-$NAMESPACE-$NAME-manifest.yaml"

verbose "Creating manifest '$cas_manifest' for CAS provsioning"

# next version: USE default external  manifest -> which can use $NAME and $NAMESPACE or fixed names

# patch the cas to enable health checks (only works on a provisioned cas)
kubectl patch cas $NAME --type='json' -p='[{"op": "replace", "path": "/spec/livenessProbe/enabled", "value": true}, {"op": "replace", "path": "/spec/startupProbe/enabled", "value": true}]'
if [[ $NO_BACKUP -eq 0 ]]; then
  verbose "Creating/Applying CAS CR for Production"
  # patch the cas to enable backup-controller
  patches="{\"op\": \"replace\", \"path\": \"/spec/backup-controller/enabled\", \"value\": true,}, {\"op\": \"replace\", \"path\": \"/spec/backup-controller/session\", \"value\": \"${POLICY_NAME}/register\",},{\"op\": \"replace\", \"path\": \"/spec/backup-controller/image\", \"value\": \"$IMAGE_REPO/backup-controller:$VERSION\",},"
  kubectl patch cas $NAME --type='json' -p='['"$patches"']'
fi

kubectl get cas $NAME -n $NAMESPACE -o yaml > $cas_manifest

verbose "The manifest of CAS instance $NAME is stored in $cas_manifest"
verbose "  - You can modify the metadata and spec fields of the manifest and apply the changes with 'kubectl apply -f \"$cas_manifest\""
verbose "The owner identity of CAS $NAME is stored in directory \"$TARGET_DIR/identity\""

kill $SERVICE_PID

fi

if [ "$SVC" == "vault" ] ; then

verbose "Retrieving MrEnclaves for vault, vault-init and vault-statement-verifier"

export VAULT_IMAGE_REPO="registry.scontain.com/scone.cloud/vault"
export VAULT_IMAGE_TAG="5.8.0-rc.1"
export VAULT_IMAGE="$VAULT_IMAGE_REPO:$VAULT_IMAGE_TAG"
export VAULT_DEFAULT_HEAP_MRENCLAVE="$(docker run -t --rm --cap-add IPC_LOCK -e SCONE_HASH=1 $VAULT_IMAGE vault | tr -d '\r')"
export VAULT_1G_MRENCLAVE="$(docker run -t --rm --cap-add IPC_LOCK -e SCONE_HASH=1 -e SCONE_HEAP=1G $VAULT_IMAGE vault | tr -d '\r')"
export VAULT_2G_MRENCLAVE="$(docker run -t --rm --cap-add IPC_LOCK -e SCONE_HASH=1 -e SCONE_HEAP=2G $VAULT_IMAGE vault | tr -d '\r')"
export VAULT_8G_MRENCLAVE="$(docker run -t --rm --cap-add IPC_LOCK -e SCONE_HASH=1 -e SCONE_HEAP=8G $VAULT_IMAGE vault | tr -d '\r')"
export VAULTINIT_DEFAULT_HEAP_MRENCLAVE=$(docker run -t --rm -e SCONE_HASH=1 $VAULT_IMAGE vault-init |tr -d '\r')
export VAULTINIT_2G_MRENCLAVE=$(docker run -t --rm -e SCONE_HASH=1 -e SCONE_HEAP=2G $VAULT_IMAGE vault-init |tr -d '\r')
export VERIFIER_MRENCLAVE=$(docker run -t --rm -e SCONE_HASH=1 $VAULT_IMAGE vault-statement-verifier |tr -d '\r')

export OWNER_ID=$RANDOM$RANDOM
export CLUSTER_SCONE_CAS_ADDR="$SVCNAME.$NAMESPACE"

# In the session yaml files on the vault-init image there are variables defined with
# $$SCONE::xxxxx$$. These have to be escaped when the files are injected
# into resources/owner/session.yaml. When escaping $$ with \$\$ that turns into
# \$\$SCONE::. In the docker container below, where the sessions are created, this is
# interpreted as \$\ follwed by $SCONE, and we get an error because $SCONE is not set.
# To hack our way around this, we set the SCONE env var to '$SCONE'. When doing the
#  docker run below, we pass SCONE_ESCAPE_HACK to the docker container as the vaule
# of the the SCONE env var.
export SCONE_ESCAPE_HACK="\$SCONE"

verbose "Attesting the cas '$SCONE_CAS_ADDR' and creating sessions"

sleep 5
kubectl port-forward service/$SVCNAME $CAS_CLIENT_PORT:$CAS_CLIENT_PORT --namespace "$NAMESPACE" --address=0.0.0.0 &
SERVICE_PID=$!
sleep 5
kill -0 $SERVICE_PID &>/dev/null || error_exit "It looks like that either port $CAS_CLIENT_PORT is not available on your local machine or the service $SVCNAME is not running. Bailing!"

docker run -it --rm \
    --network=host \
    --add-host=host.docker.internal:host-gateway \
    -e OWNER_ID="$OWNER_ID" \
    -e SCONE_CAS_ADDR="host.docker.internal" \
    -e CLUSTER_SCONE_CAS_ADDR="$CLUSTER_SCONE_CAS_ADDR" \
    -e CAS_CLIENT_PORT="$CAS_CLIENT_PORT" \
    -e VAULT_DEFAULT_HEAP_MRENCLAVE="$VAULT_DEFAULT_HEAP_MRENCLAVE" \
    -e VAULT_1G_MRENCLAVE="$VAULT_1G_MRENCLAVE" \
    -e VAULT_2G_MRENCLAVE="$VAULT_2G_MRENCLAVE" \
    -e VAULT_8G_MRENCLAVE="$VAULT_8G_MRENCLAVE" \
    -e VAULTINIT_DEFAULT_HEAP_MRENCLAVE="$VAULTINIT_DEFAULT_HEAP_MRENCLAVE" \
    -e VAULTINIT_2G_MRENCLAVE="$VAULTINIT_2G_MRENCLAVE" \
    -e VERIFIER_MRENCLAVE="$VERIFIER_MRENCLAVE" \
    -e SCONE="$SCONE_ESCAPE_HACK" \
    $VAULT_IMAGE \
    sh -c "scone cas attest -G host.docker.internal && scone cas set-default host.docker.internal && export SCONE_CAS_ADDR=\$CLUSTER_SCONE_CAS_ADDR && scone session create --use-env /opt/vault/resources/owner/session.yml && scone session create --use-env /opt/vault/resources/owner/verify.yml"

export vault_manifest="$TARGET_DIR/owner-config/vault-$NAMESPACE-$VAULT_NAME-manifest.yaml"

verbose "Creating manifest '$vault_manifest' for Vault provisioning"

cat > "$vault_manifest" <<EOF
apiVersion: services.scone.cloud/v1beta1
kind: Vault
metadata:
  name: "$VAULT_NAME"
  namespace: "$NAMESPACE"
spec:
  server:
    dev:
      enabled: false
    dataStorage:
      enabled: false
    image:
      repository: "$VAULT_IMAGE_REPO"
      tag: "$VAULT_IMAGE_TAG"
      pullPolicy: Always
    postStart:
    - /bin/bash
    - -c
    - "/usr/local/bin/provision-vault.sh && /usr/local/bin/bootstrap-vault.sh"
    resources:
      limits:
        sgx.intel.com/enclave: "1"
        memory: "12G"
      requests:
        memory: "10G"
    extraEnvironmentVars:
      SCONE_HEAP: "8G"
      SCONE_CAS_ADDR: "$SCONE_CAS_ADDR"
      SCONE_LAS_ADDR: "\$(HOST_IP)"
      VAULT_ADDR: "https://localhost:8200"
      OWNER_ID: "$OWNER_ID"
      SCONE_CONFIG_ID: "vault-\$(OWNER_ID)/dev"
      VAULTINIT_AUTO_PROVISIONING_CONFIG_ID: "vault-init-auto-\$(OWNER_ID)/dev"
      VAULTINIT_REGISTER_CONFIG_ID: "vault-init-parent-\$(OWNER_ID)/dev"
      SCONE_VERSION: "1"
    readinessProbe:
      enabled: false
  injector:
    enabled: false
  global:
    imagePullSecrets:
      - name: sconeapps
EOF

verbose "Creating Vault service"

kubectl create -f "$vault_manifest"

kubectl get vault $VAULT_NAME

verbose "The vault CR $VAULT_NAME in namespace $NAMESPACE has been provisioned."

kill $SERVICE_PID

fi
exit 0
